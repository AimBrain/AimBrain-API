# Modules

AimBrain supports **multiple biometric modalities** (modules) as part of its authentication platform. These modules can be used together (e.g. to **step-up the authentication on high risk actions**) or separately, depending on the specific use-case. Because AimBrain offers a public API, any module can be used in a **cross-channel context** (e.g. same Voice Module with mobile banking application and customer call center).

![AimBrain Modules](images/modules.png)

At the core AimBrain uses advanced **Deep Learning** algorithms based on state of the art, PhD level, scientific research. The technology has **multiple patents pending in UK and US**.

## Behavioural

With the behavioural modality AimBrain uses machine learning to track not *what* the user enters, but *how* they enter it.  AimBrain monitors features such as touch pressure, typing speed, as well as movement.

The technology works in **mobile applications and online websites**.


<aside class="notice">
Behavioural tempalte is unique per (user id, device) tuple.
</aside>

## Facial

The technology works in **mobile applications and online websites**.

Liveliness detection done via **random-challenge request**.

<aside class="notice">
Facial template is unique user id.
</aside>

## Voice

The technology is **language agnostic** and supports **free speech as well as set-phrase authentication**.

Liveliness detection done via **spoken challenge-response token**.

Works in **mobile apps, online websites and call centres**.


<aside class="notice">
Currently in testing with alpha customers.
</aside>
